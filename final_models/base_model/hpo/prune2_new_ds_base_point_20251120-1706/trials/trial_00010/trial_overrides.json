{
    "training.epochs": 100,
    "training.lr": 0.0013588204034222424,
    "training.weight_decay": 0.003948814325573004,
    "training.grad_clip": 0.30000000000000004,
    "model.hidden_dims": [
        512,
        512,
        256
    ],
    "model.dropout": 0.15000000000000002,
    "model.activation": "tanh",
    "model.batchnorm": true,
    "data.batch_size": 512,
    "training.point_loss": "mse"
}